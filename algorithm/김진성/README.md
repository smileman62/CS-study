# 버블정렬 (Bubble sort) 

### 서로 인접한 두 원소를 검사하여 정렬하는 알고리즘
- 인접한 2개의 레코드를 비교하여 크기가 순서대로 되어 있지 않으면 서로 교환한다.

첫 번째 자료와 두 번째 자료, 두번째 자료와 세 번째 자료를... (마지막-1)번째 자료와 마지막 자료를 비교하여 교환하면서 자료를 정렬한다.

1회전을 수행하고 나면 가장 큰 자료가 맨 뒤로 이동하므로, 2회전에서는 맨 끝에 있는 자료는 정렬에서 제외도고, 2회전을 수행하고 나면 끝에서 두 번쨰 자료까지는 정렬에서 제외된다.

이렇게 정렬을 1회전 수행할 때마다 정렬에서 제외되는 데이터가 하나씩 늘어난다.

### 버블정렬 (Bubble sort) 알고리즘의 예제
![alt](https://gmlwjd9405.github.io/images/algorithm-bubble-sort/bubble-sort.png)

### 버블정렬 (bubble sort) 알고리즘의 특징
장점
- 구현이 매우 간단하다.

단점
- 하나의 요소가 가장 왼쪽에서 가장 오른쪽으로 이동하기 위해서는 배열에서 모든 다른 요소들과 교환되어야한다.
- 특히 특정 요소가 최종 정렬 위치에 이미 있는 경우라도 교환되는 일이 일어난다.

일반적으로 자료의 교환작업(swap)이 자료의 이동작업(move)보다 더 복잡하기 때문에 버블 정렬은 단순성에도 불구하고 거의 **쓰이지 않는다.**

### 버블 정렬(bubble sort)의 시간복잡도

비교 횟수
- 최상, 평균, 최악 모두 일정
- n-1, n-2, … , 2, 1 번 = n(n-1)/2

교환 횟수
- 입력 자료가 역순으로 정렬되어 있는 최악의 경우, 한 번 교환하기 위하여 3번의 이동(SWAP 함수의 작업)이 필요하므로 (비교 횟수 * 3) 번 = 3n(n-1)/2
- 입력 자료가 이미 정렬되어 있는 최상의 경우, 자료의 이동이 발생하지 않는다.

### T(n) = O(n^2)

---

# 선택정렬 (selection sort)

### 제자리 정렬(in-place sorting) 알고리즘 중 하나
입력 배열(정렬되지 않은 값들) 이외에 다른 추가 메모리를 요구하지 않는 정렬 방법

해당 순서에 원소를 넣을 위치는 이미 정해져 있고, 어떤 원소를 넣을지 선택하는 알고리즘
- 첫 번째 순서에는 첫 번쨰 위치에 가장 최솟값을 넣는다.
- 두 번째 순서에는 두 번째 위치에 남은 값 중에서의 최솟값을 넣는다.

### 선택 정렬(selection sort) 알고리즘의 구체적인 개념
- 선택 정렬은 첫 번째 자료를 두 번째 자료부터 마지막 자료까지 차례대로 비교하여 가장 작은 값을 찾아 첫 번째에 놓고, 두 번째 자료를 세 번째 자료부터 마지막 자료까지와 차례대로 비교하여 그 중 가장 작은 값을 찾아 두 번째 위치에 놓는 과정을 반복하며 정렬을 수행한다.
- **1회전을 수행하고 나면 가장 작은 값의 자료가 맨 앞에 오게 되므로** 그 다음 회전에서는 두 번째 자료를 가지고 비교한다. 마찬가지로 3회전에서는 세 번째 자료를 정렬한다.

### 선택정렬 (selection sort) 알고리즘의 예제
![alt](https://gmlwjd9405.github.io/images/algorithm-selection-sort/selection-sort.png)

### 선택정렬 (selection sort) 알고리즘의 특징
장점
- 자료 이동 횟수가 미리 결정된다.

단점
- 안정성을 만족하지 않는다.
- 즉, 값이 같은 레코드가 있는 경우에 상대적인 위치가 변경될 수 있다.

### 선택정렬 (selection sort) 시간복잡도

**비교 횟수**
- 두 개의 for 루프의 실행 횟수
- 외부 루프: (n-1)번
- 내부 루프(최솟값 찾기): n-1, n-2, … , 2, 1 번

**교환 횟수**
- 외부 루프의 실행 횟수와 동일. 즉, 상수 시간 작업
- 한 번 교환하기 위하여 3번의 이동(SWAP 함수의 작업)이 필요하므로 3(n-1)번

### T(n) = (n-1) + (n-2) + … + 2 + 1 = n(n-1)/2 = **O(n^2)**

---

# 삽입 정렬(insertion sort)

## 삽입 정렬(insertion sort) 알고리즘 개념 요약
- 새로운 카드를 기존의 정렬된 카드 사이의 올바른 자리를 찾아 삽입한다.
- 새로 삽입될 카드의 수만큼 반복하게 되면 전체 카드가 정렬된다.
- 자료 배열의 모든 요소를 앞에서부터 차례대로 **이미 정렬된 배열 부분과 비교 하여**, 자신의 위치를 찾아 삽입함으로써 정렬을 완성하는 알고리즘
- 매 순서마다 해당 원소를 삽입할 수 있는 위치를 찾아 해당 위치에 넣는다.

## 삽입 정렬(insertion sort) 알고리즘의 구체적인 개념
- 삽입 정렬은 두 번째 자료부터 시작하여 그 앞(왼쪽)의 자료들과 비교하여 삽입할 위치를 지정한 후 자료를 뒤로 옮기고 지정한 자리에 자료를 삽입하여 정렬하는 알고리즘이다.
- 즉, 두 번째 자료는 첫 번째 자료, 세 번째 자료는 두 번째와 첫 번째 자료, 네 번째 자료는 세 번째, 두 번째, 첫 번째 자료와 비교한 후 자료가 삽입될 위치를 찾는다. 자료가 삽입될 위치를 찾았다면 그 위치에 자료를 삽입하기 위해 자료를 한 칸씩 뒤로 이동시킨다.
- 처음 Key 값은 두 번째 자료부터 시작한다.

## 삽입 정렬(insertion sort) 알고리즘의 예제
배열에 8, 5, 6, 2, 4가 저장되어 있다고 가정하고 자료를 오름차순으로 정렬해 보자.

![](https://gmlwjd9405.github.io/images/algorithm-insertion-sort/insertion-sort.png)

1회전:
- 두 번째 자료인 5를 Key로 해서 그 이전의 자료들과 비교한다.
- Key 값 5와 첫 번째 자료인 8을 비교한다. 8이 5보다 크므로 8을 5자리에 넣고 Key 값 5를 8의 자리인 첫 번째에 기억시킨다.

2회전:
- 세 번째 자료인 6을 Key 값으로 해서 그 이전의 자료들과 비교한다.
- Key 값 6과 두 번째 자료인 8을 비교한다. 8이 Key 값보다 크므로 8을 6이 있던 세 번째 자리에 기억시킨다.
- Key 값 6과 첫 번째 자료인 5를 비교한다. 5가 Key 값보다 작으므로 Key 값 6을 두 번째 자리에 기억시킨다.

3회전: 네 번째 자료인 2를 Key 값으로 해서 그 이전의 자료들과 비교한다.
- Key 값 2와 세 번째 자료인 8을 비교한다. 8이 Key 값보다 크므로 8을 2가 있던 네 번째 자리에 기억시킨다.
- Key 값 2와 두 번째 자료인 6을 비교한다. 6이 Key 값보다 크므로 6을 세 번째 자리에 기억시킨다.
- Key 값 2와 첫 번째 자료인 5를 비교한다. 5가 Key 값보다 크므로 5를 두 번째 자리에 넣고 그 자리에 Key 값 2를 기억시킨다.

4회전: 다섯 번째 자료인 4를 Key 값으로 해서 그 이전의 자료들과 비교한다.
- Key 값 4와 네 번째 자료인 8을 비교한다. 8이 Key 값보다 크므로 8을 다섯 번째 자리에 기억시킨다.
- Key 값 4와 세 번째 자료인 6을 비교한다. 6이 Key 값보다 크므로 6을 네 번째 자리에 기억시킨다.
- Key 값 4와 두 번째 자료인 5를 비교한다. 5가 Key 값보다 크므로 5를 세 번째 자리에 기억시킨다.
- Key 값 4와 첫 번째 자료인 2를 비교한다. 2가 Key 값보다 작으므로 4를 두 번째 자리에 기억시킨다.

## 삽입 정렬(insertion sort) 알고리즘의 특징
**장점**
- 안정한 정렬 방법
- 레코드의 수가 적을 경우 알고리즘 자체가 매우 간단하므로 다른 복잡한 정렬 방법보다 유리할 수 있다.
- 대부분위 레코드가 이미 정렬되어 있는 경우에 매우 효율적일 수 있다.

**단점**
- 비교적 많은 레코드들의 이동을 포함한다.
- 레코드 수가 많고 레코드 크기가 클 경우에 적합하지 않다.

## 삽입 정렬(insertion sort)의 시간복잡도
### 최선의 경우
**비교 횟수**
- 이동 없이 1번의 비교만 이루어진다.

**외부 루프**
- (n-1)번
### Best T(n) = O(n)
### 최악의 경우(입력 자료가 역순일 경우)
**비교 횟수**
- 외부 루프 안의 각 반복마다 i번의 비교 수행
- 외부 루프: (n-1) + (n-2) + … + 2 + 1 = n(n-1)/2 = O(n^2)

**교환 횟수**
- 외부 루프의 각 단계마다 (i+2)번의 이동 발생
- n(n-1)/2 + 2(n-1) = (n^2+3n-4)/2 = O(n^2)
### Worst T(n) = O(n^2)

---

# 퀵 정렬(quick sort)

## 퀵 정렬(quick sort) 알고리즘의 개념 요약
- ‘찰스 앤터니 리처드 호어(Charles Antony Richard Hoare)’가 개발한 정렬 알고리즘
- 퀵 정렬은 불안정 정렬 에 속하며, 다른 원소와의 비교만으로 정렬을 수행하는 비교 정렬 에 속한다.
- 분할 정복 알고리즘의 하나로, 평균적으로 매우 빠른 수행 속도를 자랑하는 정렬 방법
- 합병 정렬(merge sort)과 달리 퀵 정렬은 리스트를 비균등하게 분할한다.

## 분할 정복(divide and conquer) 방법
- 문제를 작은 2개의 문제로 분리하고 각각을 해결한 다음, 결과를 모아서 원래의 문제를 해결하는 전략이다.
- 분할 정복 방법은 대개 순환 호출을 이용하여 구현한다.

**과정 설명**
1. 리스트 안에 있는 한 요소를 선택한다. 이렇게 고른 원소를 피벗(pivot) 이라고 한다.
2. 피벗을 기준으로 피벗보다 작은 요소들은 모두 피벗의 왼쪽으로 옮겨지고 피벗보다 큰 요소들은 모두 피벗의 오른쪽으로 옮겨진다. (피벗을 중심으로 왼쪽: 피벗보다 작은 요소들, 오른쪽: 피벗보다 큰 요소들)
3. 피벗을 제외한 왼쪽 리스트와 오른쪽 리스트를 다시 정렬한다.
- 분할된 부분 리스트에 대하여 순환 호출 을 이용하여 정렬을 반복한다.
- 부분 리스트에서도 다시 피벗을 정하고 피벗을 기준으로 2개의 부분 리스트로 나누는 과정을 반복한다.
4. 부분 리스트들이 더 이상 분할이 불가능할 때까지 반복한다.
- 리스트의 크기가 0이나 1이 될 때까지 반복한다.

![](https://gmlwjd9405.github.io/images/algorithm-quick-sort/quick-sort-concepts.png)

## 퀵 정렬(quick sort) 알고리즘의 구체적인 개념
- 하나의 리스트를 피벗(pivot)을 기준으로 두 개의 비균등한 크기로 분할하고 분할된 부분 리스트를 정렬한 다음, 두 개의 - 정렬된 부분 리스트를 합하여 전체가 정렬된 리스트가 되게 하는 방법이다.

퀵 정렬은 다음의 단계들로 이루어진다.
- **분할(Divide)**: 입력 배열을 피벗을 기준으로 비균등하게 2개의 부분 배열(피벗을 중심으로 왼쪽: 피벗보다 작은 요소들, 오른쪽: 피벗보다 큰 요소들)로 분할한다.
- **정복(Conquer)**: 부분 배열을 정렬한다. 부분 배열의 크기가 충분히 작지 않으면 순환 호출 을 이용하여 다시 분할 정복 방법을 적용한다.
- **결합(Combine)**: 정렬된 부분 배열들을 하나의 배열에 합병한다.
순환 호출이 한번 진행될 때마다 최소한 하나의 원소(피벗)는 최종적으로 위치가 정해지므로, 이 알고리즘은 반드시 끝난다는 것을 보장할 수 있다.

## 퀵 정렬(quick sort) 알고리즘의 예제
배열에 5, 3, 8, 4, 9, 1, 6, 2, 7이 저장되어 있다고 가정하고 자료를 오름차순으로 정렬해 보자.
퀵 정렬에서 피벗을 기준으로 두 개의 리스트로 나누는 과정

![](https://gmlwjd9405.github.io/images/algorithm-quick-sort/quick-sort2.png)
피벗 값을 입력 리스트의 첫 번째 데이터로 하자. (다른 임의의 값이어도 상관없다.)

2개의 인덱스 변수(low, high)를 이용해서 리스트를 두 개의 부분 리스트로 나눈다.

**1회전: 피벗이 5인 경우,**
1. low는 왼쪽에서 오른쪽으로 탐색해가다가 피벗보다 큰 데이터(8)을 찾으면 멈춘다.
2. high는 오른쪽에서 왼쪽으로 탐색해가다가 피벗보다 작은 데이터(2)를 찾으면 멈춘다.
3. low와 high가 가리키는 두 데이터를 서로 교환한다.
4. 이 탐색-교환 과정은 low와 high가 엇갈릴 때까지 반복한다.

**2회전: 피벗(1회전의 왼쪽 부분리스트의 첫 번째 데이터)이 1인 경우,**
- 위와 동일한 방법으로 반복한다.

**3회전: 피벗(1회전의 오른쪽 부분리스트의 첫 번째 데이터)이 9인 경우,**

- 위와 동일한 방법으로 반복한다.

## 퀵 정렬(quick sort) 알고리즘의 특징
**장점**
- 속도가 빠르다.
- 시간 복잡도가 O(nlog₂n)를 가지는 다른 정렬 알고리즘과 비교했을 때도 가장 빠르다.
- 추가 메모리 공간을 필요로 하지 않는다.
- 퀵 정렬은 O(log n)만큼의 메모리를 필요로 한다.

**단점**
- 정렬된 리스트에 대해서는 퀵 정렬의 불균형 분할에 의해 오히려 수행시간이 더 많이 걸린다.
- 퀵 정렬의 불균형 분할을 방지하기 위하여 피벗을 선택할 때 더욱 리스트를 균등하게 분할할 수 있는 데이터를 선택한다.

EX) 리스트 내의 몇 개의 데이터 중에서 크기순으로 중간 값(medium)을 피벗으로 선택한다.

## 퀵 정렬(quick sort)의 시간복잡도
최선의 경우
- 비교 횟수

![](https://gmlwjd9405.github.io/images/algorithm-quick-sort/sort-time-complexity-etc1.png)
### 순환 호출의 깊이
- 레코드의 개수 n이 2의 거듭제곱이라고 가정(n=2^k)했을 때, n=2^3의 경우, 2^3 -> 2^2 -> 2^1 -> 2^0 순으로 줄어들어 순환 호출의 깊이가 3임을 알 수 있다.
- 이것을 일반화하면 n=2^k의 경우, k(k=log₂n)임을 알 수 있다.
- k=log₂n

### 각 순환 호출 단계의 비교 연산
- 각 순환 호출에서는 전체 리스트의 대부분의 레코드를 비교해야 하므로 평균 n번 정도의 비교가 이루어진다.
- 평균 n번

**순환 호출의 깊이 * 각 순환 호출 단계의 비교 연산 = nlog₂n**

### 이동 횟수
- 비교 횟수보다 적으므로 무시할 수 있다.

**최선의 경우 T(n) = O(nlog₂n)**

### 최악의 경우
- 리스트가 계속 불균형하게 나누어지는 경우 (특히, 이미 정렬된 리스트에 대하여 퀵 정렬을 실행하는 경우)

![](https://gmlwjd9405.github.io/images/algorithm-quick-sort/sort-time-complexity-etc2.png)

### 비교 횟수
- 순환 호출의 깊이
- 레코드의 개수 n이 2의 거듭제곱이라고 가정(n=2^k)했을 때, 순환 호출의 깊이는 n임을 알 수 있다.
- n

### 각 순환 호출 단계의 비교 연산
- 각 순환 호출에서는 전체 리스트의 대부분의 레코드를 비교해야 하므로 평균 n번 정도의 비교가 이루어진다.
- 평균 n번
- 순환 호출의 깊이 * 각 순환 호출 단계의 비교 연산 = n^2

### 이동 횟수
- 비교 횟수보다 적으므로 무시할 수 있다.

**최악의 경우 T(n) = O(n^2)**

### 평균
- 평균 T(n) = O(nlog₂n)
- 시간 복잡도가 O(nlog₂n)를 가지는 다른 정렬 알고리즘과 비교했을 때도 가장 빠르다.
- 퀵 정렬이 불필요한 데이터의 이동을 줄이고 먼 거리의 데이터를 교환할 뿐만 아니라, 한 번 결정된 피벗들이 추후 연산에서 제외되는 특성 때문이다.

---

# 합병 정렬(merge sort)

## 합병 정렬(merge sort) 알고리즘의 개념 요약
- ‘존 폰 노이만(John von Neumann)’이라는 사람이 제안한 방법
- 일반적인 방법으로 구현했을 때 이 정렬은 안정 정렬 에 속하며, 분할 정복 알고리즘의 하나 이다.

## 분할 정복(divide and conquer) 방법
- 문제를 작은 2개의 문제로 분리하고 각각을 해결한 다음, 결과를 모아서 원래의 문제를 해결하는 전략이다.
- 분할 정복 방법은 대개 순환 호출을 이용하여 구현한다.

## 과정 설명
- 리스트의 길이가 0 또는 1이면 이미 정렬된 것으로 본다.
- 그렇지 않은 경우에는 정렬되지 않은 리스트를 절반으로 잘라 비슷한 크기의 두 부분 리스트로 나눈다.

- 각 부분 리스트를 재귀적으로 합병 정렬을 이용해 정렬한다.
- 두 부분 리스트를 다시 하나의 정렬된 리스트로 합병한다.

## 합병 정렬(merge sort) 알고리즘의 구체적인 개념
- 하나의 리스트를 두 개의 균등한 크기로 분할하고 분할된 부분 리스트를 정렬한 다음, 두 개의 정렬된 부분 리스트를 합하여 전체가 정렬된 리스트가 되게 하는 방법이다.

### 합병 정렬은 다음의 단계들로 이루어진다.
- 분할(Divide): 입력 배열을 같은 크기의 2개의 부분 배열로 분할한다.
- 정복(Conquer): 부분 배열을 정렬한다. 부분 배열의 크기가 충분히 작지 않으면 순환 호출 을 이용하여 다시 분할 정복 방법을 적용한다.
- 결합(Combine): 정렬된 부분 배열들을 하나의 배열에 합병한다.

### 합병 정렬의 과정
- 추가적인 리스트가 필요하다.
- 각 부분 배열을 정렬할 때도 합병 정렬을 순환적으로 호출하여 적용한다.
- 합병 정렬에서 실제로 정렬이 이루어지는 시점은 2개의 리스트를 합병(merge)하는 단계 이다.

![](https://gmlwjd9405.github.io/images/algorithm-merge-sort/merge-sort-concepts.png)

## 합병 정렬(merge sort) 알고리즘의 예제
- 배열에 27, 10, 12, 20, 25, 13, 15, 22이 저장되어 있다고 가정하고 자료를 오름차순으로 정렬해 보자.

### 2개의 정렬된 리스트를 합병(merge)하는 과정
- 2개의 리스트의 값들을 처음부터 하나씩 비교하여 두 개의 리스트의 값 중에서 더 작은 값을 새로운 리스트(sorted)로 옮긴다.
- 둘 중에서 하나가 끝날 때까지 이 과정을 되풀이한다.
- 만약 둘 중에서 하나의 리스트가 먼저 끝나게 되면 나머지 리스트의 값들을 전부 새로운 리스트(sorted)로 복사한다.
- 새로운 리스트(sorted)를 원래의 리스트(list)로 옮긴다.

![](https://gmlwjd9405.github.io/images/algorithm-merge-sort/merge-sort.png)

## 합병 정렬(merge sort) 알고리즘의 특징
### 단점
- 만약 레코드를 배열(Array)로 구성하면, 임시 배열이 필요하다.
- 제자리 정렬(in-place sorting)이 아니다.
- 레코드들의 크기가 큰 경우에는 이동 횟수가 많으므로 매우 큰 시간적 낭비를 초래한다.
### 장점
- 안정적인 정렬 방법
- 데이터의 분포에 영향을 덜 받는다. 즉, 입력 데이터가 무엇이든 간에 정렬되는 시간은 동일하다. (O(nlog₂n)로 동일)
만약 레코드를 연결 리스트(Linked List)로 구성하면, 링크 인덱스만 변경되므로 데이터의 이동은 무시할 수 있을 정도로 작아진다.
- 제자리 정렬(in-place sorting)로 구현할 수 있다.
- 따라서 크기가 큰 레코드를 정렬할 경우에 연결 리스트를 사용한다면, 합병 정렬은 퀵 정렬을 포함한 다른 어떤 졍렬 방법보다 효율적이다.

## 합병 정렬(merge sort)의 시간복잡도
시간복잡도를 계산한다면

### 분할 단계
- 비교 연산과 이동 연산이 수행되지 않는다.
### 합병 단계
- 비교 횟수
![](https://gmlwjd9405.github.io/images/algorithm-merge-sort/sort-time-complexity-etc.png)
**순환 호출의 깊이 (합병 단계의 수)**
- 레코드의 개수 n이 2의 거듭제곱이라고 가정(n=2^k)했을 때, n=2^3의 경우, 2^3 -> 2^2 -> 2^1 -> 2^0 순으로 줄어들어 순환 호출의 깊이가 3임을 알 수 있다.
- 이것을 일반화하면 n=2^k의 경우, k(k=log₂n)임을 알 수 있다.

k=log₂n

**각 합병 단계의 비교 연산**
- 크기 1인 부분 배열 2개를 합병하는 데는 최대 2번의 비교 연산이 필요하고, 부분 배열의 쌍이 4개이므로 24=8번의 비교 연산이 필요하다.
- 다음 단계에서는 크기 2인 부분 배열 2개를 합병하는 데 최대 4번의 비교 연산이 필요하고, 부분 배열의 쌍이 2개이므로 42=8번의 비교 연산이 필요하다.
- 마지막 단계에서는 크기 4인 부분 배열 2개를 합병하는 데는 최대 8번의 비교 연산이 필요하고, 부분 배열의 쌍이 1개이므로 8*1=8번의 비교 연산이 필요하다.
- 이것을 일반화하면 하나의 합병 단계에서는 최대 n번의 비교 연산을 수행함을 알 수 있다.

**최대 n번**

**순환 호출의 깊이 만큼의 합병 단계 * 각 합병 단계의 비교 연산 = nlog₂n**

**이동 횟수**
순환 호출의 깊이 (합병 단계의 수)
- k=log₂n

각 합병 단계의 이동 연산
- 임시 배열에 복사했다가 다시 가져와야 되므로 이동 연산은 총 부분 배열에 들어 있는 요소의 개수가 n인 경우, 레코드의 이동이 2n번 발생한다.

**순환 호출의 깊이 만큼의 합병 단계 * 각 합병 단계의 이동 연산 = 2nlog₂n**

**T(n) = nlog₂n(비교) + 2nlog₂n(이동) = 3nlog₂n = O(nlog₂n)**

---

# 힙 정렬(Heap sort)

## 자료구조 ‘힙(heap)’
- 완전 이진 트리의 일종으로 우선순위 큐를 위하여 만들어진 자료구조
- 최댓값, 최솟값을 쉽게 추출할 수 있는 자료구조

![](https://gmlwjd9405.github.io/images/data-structure-heap/types-of-heap.png)

## 힙 정렬(heap sort) 알고리즘의 개념 요약
- 최대 힙 트리나 최소 힙 트리를 구성해 정렬을 하는 방법
- 내림차순 정렬을 위해서는 최대 힙을 구성하고 오름차순 정렬을 위해서는 최소 힙을 구성하면 된다.

### 과정 설명
1. 정렬해야 할 n개의 요소들로 최대 힙(완전 이진 트리 형태)을 만든다. (내림차순을 기준으로 정렬)
2. 그 다음으로 한 번에 하나씩 요소를 힙에서 꺼내서 배열의 뒤부터 저장하면 된다.
3. 삭제되는 요소들(최댓값부터 삭제)은 값이 감소되는 순서로 정렬되게 된다.

### 내림차순 정렬을 위한 최대 힙(max heap)의 구현
- 힙(heap)은 1차원 배열로 쉽게 구현될 수 있다.
- 정렬해야 할 n개의 요소들을 1차원 배열에 기억한 후 최대 힙 삽입을 통해 차례대로 삽입한다.
- 최대 힙으로 구성된 배열에서 최댓값부터 삭제한다.

### 1. 최대 힙(max heap)의 삽입
1. 힙에 새로운 요소가 들어오면, 일단 새로운 노드를 힙의 마지막 노드에 이어서 삽입한다.
2. 새로운 노드를 부모 노드들과 교환해서 힙의 성질을 만족시킨다.

![](https://gmlwjd9405.github.io/images/data-structure-heap/maxheap-insertion.png)

### 2. 최대 힙(max heap)의 삭제
1. 최대 힙에서 최댓값은 루트 노드이므로 루트 노드가 삭제된다.
- 최대 힙(max heap)에서 삭제 연산은 최댓값을 가진 요소를 삭제하는 것이다.
2. 삭제된 루트 노드에는 힙의 마지막 노드를 가져온다.
3. 힙을 재구성한다.

![](https://gmlwjd9405.github.io/images/data-structure-heap/maxheap-delete.png)

## 힙 정렬(heap sort) 알고리즘의 특징
### 장점
- 시간 복잡도가 좋은편
- 힙 정렬이 가장 유용한 경우는 전체 자료를 정렬하는 것이 아니라 가장 큰 값 몇개만 필요할 때 이다.

### 힙 정렬(heap sort)의 시간복잡도
시간복잡도를 계산한다면
- 힙 트리의 전체 높이가 거의 log₂n(완전 이진 트리이므로)이므로 하나의 요소를 힙에 삽입하거나 삭제할 때 힙을 재정비하는 시간이 log₂n만큼 소요된다.
- 요소의 개수가 n개 이므로 전체적으로 O(nlog₂n)의 시간이 걸린다.

**T(n) = O(nlog₂n)**

---

# 기수 정렬(Radix sort)

## 기수 정렬(Radix sort) 알고리즘의 개념 요약
- 정수나 문자열 데이터를 자릿수별로 나누어 정렬하는 알고리즘
- **낮은 자리수(일의 자리)** 부터 차례대로 정렬을 수행하면서 전체를 정렬해 나감.
- 각 자릿수를 기준으로 **안정 정렬(Stable Sort, 예: Counting Sort)** 을 반복 수행함
- 속도가 빠르지만, 정수나 고정된 길이의 문자열처럼 “자릿수”가 명확한 데이터에서만 사용 가능
- 부동소수점, 음수, 가변 길이 문자열 등에는 직접 적용하기 어려움

## 과정 설명
1.	배열의 최대값(max)을 찾는다.
- 최대값을 이용해 몇 자리수까지 정렬해야 하는지 계산한다.
2. 가장 낮은 자리수(1의 자리)부터 정렬한다.
- Counting Sort 또는 Bucket Sort를 사용해 해당 자리 기준으로 안정 정렬 수행.
3. 다음 자리수(10의 자리, 100의 자리, …) 로 이동하며 정렬을 반복한다.
- 최대 자릿수까지 반복하면 전체가 정렬된다.

## 기수 정렬(Radix sort) 알고리즘의 구체적인 개념

### 기수 정렬의 과정
1. 첫번째 자리 수를 기준으로 정렬한다.
2. 두번째 자리 수를 기준으로 정렬한다.

![](https://blog.kakaocdn.net/dna/ddDUGV/btqEADkQR6A/AAAAAAAAAAAAAAAAAAAAAHTu-BHW_jUs-UkR5Uii4ZZ7EzPmD3i4Gxk2xQdVCy6Q/img.gif?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1764514799&allow_ip=&allow_referer=&signature=HpmKLOZEmCAAMpldYw0UzHtohTU%3D)

## 기수 정렬(Radix sort) 알고리즘의 특징
### 장점
- 정렬 속도가 매우 빠르다.
- 비교 기반 정렬(퀵, 머지 등)은 **O(n log n)** 이지만,
기수 정렬은 자릿수 k에 대해 **O(k·n)** 으로 동작.
- 안정 정렬(Stable Sort) 을 유지함
→ 동일한 값을 가진 원소의 순서가 보존됨.
- 정수나 문자열 정렬에 특히 효율적.

### 단점
**메모리 사용량이 많다.**
- Counting 배열, Output 배열 등 추가 메모리 필요.

**자릿수가 명확한 자료에만 적용 가능.**
- 실수, 음수, 다양한 길이의 문자열은 직접 정렬 불가.

**데이터 범위가 너무 크면 비효율적.**

## 기수 정렬(Radix sort)의 시간복잡도
시간복잡도를 계산한다면
- 기수 정렬은 각 자릿수마다 한 번씩 정렬을 수행하므로, 전체 자릿수를 d라 하면 정렬 과정이 d번 반복된다.
- 각 자릿수의 정렬은 보통 계수 정렬(Counting Sort) 을 사용하므로, 한 번 정렬할 때의 시간복잡도는 O(n + k)가 된다.
(여기서 n은 원소의 개수, k는 한 자리에서 가능한 숫자의 범위 예: 0~9 ⇒ 10)

**T(n) = O(d × (n + k)) == O(n)**

---

# 계수 정렬(Counting Sort)

## 계수 정렬(Counting Sort) 알고리즘의 개념 요약
- 데이터의 값(숫자 크기) 자체를 인덱스로 사용하여 정렬하는 알고리즘이다.
- 각 원소가 몇 번 등장했는지를 세어 그 빈도(count) 를 누적하여 정렬 순서를 결정한다.
- 비교 연산을 수행하지 않는 비(非)비교 기반 정렬이므로, 시간복잡도가 매우 빠르다.
- 데이터의 범위(k, 최대값)가 작고, 정수 형태로 한정될 때 매우 효율적이다.
- 그러나 데이터의 최대값이 너무 크거나 음수가 포함되면 비효율적이거나 별도 처리가 필요하다.

## 과정 설명
1. 배열에서 최댓값(max)을 찾는다.
- 최대값을 이용해 count 배열의 크기(max + 1)를 정한다.

2. count 배열을 초기화하고 각 숫자의 등장 횟수를 센다.
- [3, 1, 2, 2, 4, 5] → count = [0, 1, 2, 1, 1, 1]

3. 누적합 배열로 변환한다.
- 각 인덱스가 해당 값 이하의 원소 개수를 나타내도록 변경한다.
- count = [0, 1, 3, 4, 5, 6]

4. 뒤에서부터 탐색하며 정렬된 위치에 값을 삽입한다.
- 안정 정렬(Stable Sort)을 유지하기 위해 뒤에서부터 처리한다.

5. output 배열을 원본 배열에 복사하여 정렬 완료.

![](https://blog.kakaocdn.net/dna/QiWZZ/btq89vkmDh7/AAAAAAAAAAAAAAAAAAAAAPGMrEcgoCQnFwWCrbJbyIiCg6QMHC1lac_e5l-yWN5x/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1764514799&allow_ip=&allow_referer=&signature=wy86Ubgj%2FQ94qLuwIFk1axHgktQ%3D)

## 계수 정렬(Counting Sort) 알고리즘의 구체적인 개념
정렬될 값을 넣기 전에, 누적합 배열의 각 원소는 “해당 인덱스 이하의 값이 몇 개 존재하는가”를 의미한다.
- c1 = 1 : b1에서 b1까지 1개 자리 차지
- c2 = 2 : b2에서 b3까지 2개 자리 차지
- c3 = 1 : b4에서 b4까지 1개 자리 차지
- c4 = 1 : b5에서 b5까지 1개 자리 차지
- c5 = 1 : b6에서 b6까지 1개 자리 차지

입력 배열의 값을 차례대로 순회하여 누적합 배열에 조회하면 해당 원소가 어느 좌표로 가야 하는지 알 수 있고 출력 배열에 삽입 후 Counting Array의 값을 1 감소시켜 앞의 좌표에 넣을 수 있게끔 한다.

## 계수 정렬(Counting Sort) 알고리즘의 특징

### 장점
- 비교를 사용하지 않아 매우 빠르다.
→ O(n + k) 로 동작 (n: 원소 개수, k: 값의 범위)
- 안정 정렬(Stable Sort) 이 가능하다.
- 정수형 데이터 정렬에 최적화되어 있다.

### 단점
- 데이터의 범위(k)가 너무 크면 비효율적이다.
- count 배열의 크기가 커져 메모리 낭비 발생.
- 음수 데이터 처리 불편.
- 음수가 있으면 offset 처리가 필요하다.
- 실수나 문자열에는 직접 적용 불가.

## 계수 정렬(Counting Sort)의 시간복잡도

시간복잡도를 계산한다면
- 배열의 길이가 n, 데이터의 최댓값이 k일 때,
등장 횟수 세기, 누적합 계산, 정렬 삽입 과정 각각이 **O(n + k)** 의 시간을 사용한다.

**T(n) = O(n + k)**



# 비트마스크(Bitmask)

## 비트마스크(Bitmask) 알고리즘의 개념 요약
- 정수를 이진수로 표현하여 **집합 또는 상태를 표현**하는 알고리즘
- 각 비트는 원소의 포함 여부를 나타냄 (1: 포함, 0: 미포함)
- AND, OR, XOR, SHIFT 연산을 통해 상태를 빠르게 처리
- 부분집합, DP 상태 압축, 방문 체크 등에 사용

## 과정 설명
1. 정수를 bit 단위로 해석
2. OR → 원소 추가  
   AND → 포함 여부 확인  
   XOR → 포함 여부 반전  
   SHIFT → 상태 이동
3. 예: {1,3,4} → `1101₂` → 13

## 비트마스크(Bitmask) 알고리즘의 특징

### 장점
- 비트 연산은 O(1)
- 메모리 효율적
- 부분집합 생성이 O(2ⁿ)

### 단점
- 사용 가능한 상태 수 제한
- 직관적으로 이해가 어려울 수 있음

## 비트마스크(Bitmask)의 시간복잡도
- 비트 연산: O(1)
- 부분집합 순회: O(2ⁿ)



# 이분 탐색(Binary Search)

## 이분 탐색(Binary Search) 알고리즘의 개념 요약
- **정렬된 배열**에서 탐색 범위를 절반씩 줄이며 값 탐색
- 중앙값(mid)을 기준으로 탐색 방향 결정
- 조건을 만족할 때까지 반복 수행

## 과정 설명
1. left, right 초기화
2. mid = (left + right) / 2
3. mid 값과 target 비교
4. 범위를 절반으로 좁혀 반복

## 이분 탐색(Binary Search) 알고리즘의 특징

### 장점
- 선형 탐색 O(n) → O(log n)
- 매우 빠른 탐색 가능

### 단점
- 데이터가 정렬되어 있어야 함
- 중복 데이터 처리 시 주의 필요

## 이분 탐색(Binary Search)의 시간복잡도
**T(n) = O(log n)**



# 해시(Hash)

## 해시(Hash) 알고리즘의 개념 요약
- Key를 해시 함수로 변환해 테이블에 저장
- 평균적으로 O(1)에 검색 및 삽입 가능
- 해시 충돌 처리 필요

## 과정 설명
1. Key 입력
2. Hash 함수로 index 계산
3. 해당 index에 저장/조회

## 해시(Hash) 알고리즘의 특징

### 장점
- 매우 빠른 조회(O(1))
- Key-Value 방식에 최적

### 단점
- 해시 충돌 관리 필요
- 해시 함수 품질이 중요

## 해시(Hash)의 시간복잡도
- 평균: O(1)
- 최악: O(n)



# DFS & BFS

## DFS & BFS 알고리즘의 개념 요약
- DFS: 깊이 우선 탐색 (Stack/Recursion)
- BFS: 너비 우선 탐색 (Queue)
- 그래프 탐색 및 최단 거리 문제에서 활용

![](https://i.namu.wiki/i/QNZVYZ-2OQ4Rn4TtGdiN01gshZsrfseWqpN-cEfdX8F4BsH6GVY8GgfluRVwtfjyRZzY0rVxAmYkxzrk6EWRhw.gif)

## DFS 과정
1. 시작 정점 방문
2. 재귀 또는 스택으로 깊게 탐색
3. 백트래킹하며 복귀

## BFS 과정
1. 시작 정점을 큐에 삽입
2. 큐에서 꺼내며 인접 노드 탐색
3. 레벨 단위로 확장

## DFS & BFS 알고리즘의 특징

### 장점
- DFS: 백트래킹, 사이클 탐지 가능
- BFS: 최단 거리 탐색 가능

### 단점
- DFS: 재귀 깊이 제한
- BFS: 메모리 사용량 증가 가능

## DFS & BFS의 시간복잡도
**T(n) = O(V + E)**



# 최장 증가 수열(LIS)

## LIS 알고리즘의 개념 요약
- 증가하는 부분 수열 중 가장 긴 길이 찾기
- DP 또는 이분 탐색으로 구현
- lower_bound 활용한 최적화 방식 존재

## 과정 설명 (O(n log n))
1. 수열 순회
2. LIS 배열에서 lower_bound 탐색
3. 값 교체 또는 추가

## LIS 알고리즘의 특징

### 장점
- O(n²) → O(n log n) 최적화 가능
- 실제 LIS 추적도 가능

### 단점
- 구현 방식이 직관적이지 않음

## LIS의 시간복잡도
**T(n) = O(n log n)**



# 최소 공통 조상(LCA)

## LCA 알고리즘의 개념 요약
- 트리에서 두 노드의 공통 조상 중 가장 가까운 노드 찾기
- DFS + 희소 테이블(Binary Lifting) 방식 사용

## 과정 설명
1. DFS로 depth, parent 기록

![](https://t1.daumcdn.net/cfile/tistory/2730235058C836FE08)

2. 2ⁱ 부모 점프 테이블 생성
3. 깊이를 동일하게 맞춘 후 동시에 상승

![](https://t1.daumcdn.net/cfile/tistory/2738434C58C838180C)

6이 8보다 깊이가 더 깊으므로, 깊이가 더 낮은 쪽으로 깊이를 맞춰줘야 한다.

![](https://t1.daumcdn.net/cfile/tistory/242A364958C839BE15)

6의 2^2번째 조상은 3이고, 3은 8보다 깊이가 낮으므로 2^2번째 조상의 탐지는 중지한다.

![](https://t1.daumcdn.net/cfile/tistory/225C114B58C83A7610)

6의 2^1번째 조상을 탐색하면 2이고 8보다 깊이가 아직 깊으므로 2를 6으로 업데이트 해준다.

![](https://t1.daumcdn.net/cfile/tistory/245CBC4E58C83B7C0E)

2의 2^0번째 조상을 탐색하면 12이고 깊이가 같으므로 2를 12로 업데이트 해준다.

![](https://t1.daumcdn.net/cfile/tistory/214E0E4A58C83D8C15)

이제 깊이가 서로 같아 졌으므로, 2^k만큼 올리며 조상이 같아질 때까지 노드를 타고 올라가면 된다.

## LCA 알고리즘의 특징

### 장점
- 쿼리마다 O(log n)
- 트리 관련 문제 핵심 알고리즘

### 단점
- 전처리 O(n log n)
- 구현 난이도 높음

## LCA의 시간복잡도
- 전처리: O(n log n)
- 질의(Query): O(log n)



# 동적 계획법(DP)

## 동적 계획법(Dynamic Programming) 알고리즘의 개념 요약
- 큰 문제를 작은 문제들로 나누어 해결
- 중복 계산 결과를 저장해 재사용
- 탑다운 / 바텀업 방식 존재

## 과정 설명

동적 계획법을 활용하기 위해서는 문제가 다음과 같은 특징을 가지고 있어야한다.

1) Overlapping Subproblems(겹치는 부분 문제)

DP는 기본적으로 문제를 나누고 그 문제의 결과 값을 재활용해서 전체 답을 구한다. 그래서 동일한 작은 문제들이 반복하여 나타나는 경우에 사용이 가능하다.

즉, DP는 부분 문제의 결과를 저장하여 재 계산하지 않을 수 있어야 하는데, 해당 부분 문제가 반복적으로 나타나지 않는다면 재사용이 불가능하니 부분 문제가 중복되지 않는 경우에는 사용할 수 없다.

2) Optimal Substructure(최적 부분 구조)

부분 문제의 최적 결과 값을 사용해 전체 문제의 최적 결과를 낼 수 있는 경우를 의미한다. 그래서 특정 문제의 정답은 문제의 크기에 상관없이 항상 동일하다!

만약, A - B까지의 가장 짧은 경로를 찾고자 하는 경우를 예시로 할 때, 중간에 X가 있을 때, A - X / X - B가 많은 경로 중 가장 짧은 경로라면 전체 최적 경로도 A - X - B가 정답이 된다.

![](https://blog.kakaocdn.net/dna/dfnwTm/btqSsRROqcY/AAAAAAAAAAAAAAAAAAAAAFQ9OzX_d94_iNA5N4KHuVfsf1W3bkaP9V9q4FST8yrY/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1764514799&allow_ip=&allow_referer=&signature=bC%2FMOC7gWgI5Bf9ElOa4OQ%2BAuLQ%3D)
 
위의 그림에서 A - X 사이의 최단 거리는 AX2이고 X - B는 BX2이다. 전체 최단 경로는 AX2 - BX2이다. 다른 경로를 택한다고 해서 전체 최단 경로가 변할 수는 없다.

이와 같이, 부분 문제에서 구한 최적 결과가 전체 문제에서도 동일하게 적용되어 결과가 변하지 않을 때 DP를 사용할 수 있게 된다.


1. DP로 풀 수 있는 문제인지 확인

애초에 이 부분 부터 해결이 매우 어렵다. 우선 DP의 조건 부분에서 써내렸듯이, 현재 직면한 문제가 작은 문제들로 이루어진 하나의 함수로 표현될 수 있는지를 판단해야 한다.

즉, 위에서 쓴 조건들이 충족되는 문제인지를 한 번 체크해보는 것이 좋다.

보통 특정 데이터 내 최대화 / 최소화 계산을 하거나 특정 조건 내 데이터를 세야 한다거나 확률 등의 계산의 경우 DP로 풀 수 있는 경우가 많다.

 
2. 문제의 변수 파악

DP는 현재 변수에 따라 그 결과 값을 찾고 그것을 전달하여 재사용하는 것을 거친다.  즉, 문제 내 변수의 개수를 알아내야 한다는 것. 이것을 영어로 "state"를 결정한다고 한다.

예를 들어, 피보나치 수열에서는 n번째 숫자를 구하는 것이므로 n이 변수가 된다. 그 변수가 얼마이냐에 따라 결과값이 다르지만 그 결과를 재사용하고 있다.

또한, 문자열 간의 차이를 구할 때는 문자열의 길이, Edit 거리 등 2가지 변수를 사용한다. 해당 문제를 몰라도 된다.

또, 유명한 Knapsack 문제에서는 index, 무게로 2가지의 변수를 사용한다. 이와 같이 해당 문제에서 어떤 변수가 있는지를 파악해야 그에 따른 답을 구할 수 있다.

 
3. 변수 간 관계식 만들기

변수들에 의해 결과 값이 달라지지만 동일한 변수값인 경우 결과는 동일하다. 또한 우리는 그 결과값을 그대로 이용할 것이므로 그 관계식을 만들어낼 수 있어야 한다.

그러한 식을 점화식이라고 부르며 그를 통해 우리면 짧은 코드 내에서 반복/재귀를 통해 문제가 자동으로 해결되도록 구축할 수 있게 된다.

예를 들어 피보나치 수열에서는 f(n) = f(n-1) + f(n-2) 였다. 이는 변수의 개수, 문제의 상황마다 모두 다를 수 있다.

 
4. 메모하기

변수 간 관계식까지 정상적으로 생성되었다면 변수의 값에 따른 결과를 저장해야 한다. 이것을 메모한다고 하여 Memoization이라고 부른다.

변수 값에 따른 결과를 저장할 배열 등을 미리 만들고 그 결과를 나올 때마다 배열 내에 저장하고 그 저장된 값을 재사용하는 방식으로 문제를 해결해 나간다.

이 결과 값을 저장할 때는 보통 배열을 쓰며 변수의 개수에 따라 배열의 차원이 1~3차원 등 다양할 수 있다.

 
5. 기저 상태 파악하기

여기까지 진행했으면, 가장 작은 문제의 상태를 알아야 한다. 보통 몇 가지 예시를 직접 손으로 테스트하여 구성하는 경우가 많다. 

피보나치 수열을 예시로 들면, f(0) = 0, f(1) = 1과 같은 방식이다. 이후 두 가지 숫자를 더해가며 값을 구하지만 가장 작은 문제는 저 2개로 볼 수 있다.

해당 기저 문제에 대해 파악 후 미리 배열 등에 저장해두면 된다. 이 경우, 피보나치 수열은 매우 간단했지만 문제에 따라 좀 복잡할 수 있다.

 
6. 구현하기

개념과 DP를 사용하는 조건, DP 문제를 해결하는 과정도 익혔으니 실제로 어떻게 사용할 수 있는지를 알아보고자 한다. DP는 2가지 방식으로 구현할 수 있다.

1) Bottom-Up (Tabulation 방식) - 반복문 사용

이름에서 보이듯이, 아래에서 부터 계산을 수행 하고 누적시켜서 전체 큰 문제를 해결하는 방식이다.

메모를 위해서 dp라는 배열을 만들었고 이것이 1차원이라 가정했을 때, dp[0]가 기저 상태이고 dp[n]을 목표 상태라고 하자. Bottom-up은 dp[0]부터 시작하여 반복문을 통해 점화식으로 결과를 내서 dp[n]까지 그 값을 전이시켜 재활용하는 방식이다.

왜 Tabulation?

사실 위에서 메모하기 부분에서 Memoization이라고 했는데 Bottom-up일 때는 Tabulation이라고 부른다.

왜냐면 반복을 통해 dp[0]부터 하나 하나씩 채우는 과정을 "table-filling" 하며, 이 Table에 저장된 값에 직접 접근하여 재활용하므로 Tabulation이라는 명칭이 붙었다고 한다.

사실상 근본적인 개념은 결과값을 기억하고 재활용한다는 측면에서 메모하기(Memoization)와 크게 다르지 않다.

2) Top-Down (Memoization 방식) - 재귀 사용

이는 dp[0]의 기저 상태에서 출발하는 대신 dp[n]의 값을 찾기 위해 위에서 부터 바로 호출을 시작하여 dp[0]의 상태까지 내려간 다음 해당 결과 값을 재귀를 통해 전이시켜 재활용하는 방식이다.

피보나치의 예시처럼, f(n) = f(n-2) + f(n-1)의 과정에서 함수 호출 트리의 과정에서 보이듯, n=5일 때, f(3), f(2)의 동일한 계산이 반복적으로 나오게 된다.

이 때, 이미 이전에 계산을 완료한 경우에는 단순히 메모리에 저장되어 있던 내역을 꺼내서 활용하면 된다. 그래서 가장 최근의 상태 값을 메모해 두었다고 하여 Memoization 이라고 부른다.

## 동적 계획법(Dynamic Programming) 알고리즘의 특징

### 장점
- 중복 계산 제거로 성능 향상
- 다이나믹하게 최적해 구성 가능

### 단점
- 점화식 도출이 어려울 수 있음
- 메모리 사용량 증가 가능

## 동적 계획법(Dynamic Programming)의 시간복잡도
- 문제 구조에 따라 다름  
(ex. O(n), O(n²), O(nk))




# 세그먼트 트리(Segment Tree)

## 세그먼트 트리(Segment Tree) 알고리즘의 개념 요약
- 각 구간의 합을 트리를 활용하여 배치하여 특정 구간의 합을 빠르게 구할 수 있음
- 기존의 배열 형식을 트리로 펼쳐 전체 데이터의 범위를 절반씩 분할아여 각 구간의 합들을 저장하도록 함
- 위의 과정을 반복하여 구간 합 트리의 전체 노드를 구할 수 있음

## 과정 설명

[1,9,3,8,4,5,5,9,10,3,4,5]

![](https://mblogthumb-phinf.pstatic.net/MjAxODA1MjNfMjU0/MDAxNTI3MDQzNjk1OTUy.f9HkIyu_MJ7UxK-w9YDGc0irdFhb17Fr6iyk1pLiVrcg.ARKp3Nb8ebiOx4iU0MoaOIXunbudnMvAwB5rmLGkru8g.PNG.ndb796/image.png?type=w800)

1. 기존의 배열을 트리로 구성.
- 좌측을 우선하여 값을 추가

![](https://mblogthumb-phinf.pstatic.net/MjAxODA1MjNfODkg/MDAxNTI3MDQ1NzA1Mjgy.M3JVFOW3XJ1D703LXxBrmPT8_XPTGwVWcMgaqdPe8Jcg.O2_oLTncsUcWgdVyk7n8t15fQf7pSNasL7WgV3kPSmAg.PNG.ndb796/image.png?type=w800)

2. 최상단 노드에 전체 원소를 더한 값을 추가

![](https://mblogthumb-phinf.pstatic.net/MjAxODA1MjNfMTkx/MDAxNTI3MDQ1NjE1MTA2.027g35DrzBQE0MeuOW3ws1gE3izOAVCq5bnfON6yH_cg.YBYH9kUzWqHMNC8B_POyHsAk0xNH3hVPzqdW-7csGkUg.PNG.ndb796/image.png?type=w800)

3. 전체 인덱스의 절반으로 나누어 두번째 노드와 세번째 노드를 구함

![](https://mblogthumb-phinf.pstatic.net/MjAxODA1MjNfNDQg/MDAxNTI3MDQ2Mzg2MzAy.c5AMlXYpl0MI0vYEKk83Qf5ANciycA3cPqHEznPocyQg.p_pQrg2--R_vv-tUiv5Vgwwmujjay1CjomipG6FSBFsg.PNG.ndb796/image.png?type=w800)

4. 위 방식을 반복하여 전체 트리를 완성함. (만일 전체 인덱스의 개수가 홀수일 경우 좌측 노드에 과반으로 몰아줌.)


## 세그먼트 트리(Segment Tree) 알고리즘의 특징

### 장점
- 배열 범위에 대한 정보와 변화에 빠르게 대처할 수 있다.
- 구간 합뿐만 아니라 구간 최댓값, 최솟값, 구간 곱, 구간 XOR 등 다양한 구간 연산에 활용할 수 있다.

### 단점
- 자료구조의 개념과 구현 방식이 비교적 복잡하여 코드로 구현하는 데 시간이 걸릴 수 있다.
- 트리의 높이가 O(logN)이지만, 노드의 개수가 O(N)에 비례하기 때문에 배열 자체보다 더 많은 메모리를 사용하게 된다.

## 세그먼트 트리(Segment Tree)의 시간복잡도
- O(logn)